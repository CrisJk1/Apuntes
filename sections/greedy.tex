\newpage
\section{Algoritmos Greedy}

\subsection{Introduccion}

Un algoritmo voraz es un algoritmo que construye un objeto paso a paso, eligiendo en cada paso la mejor opcion local. En algunos casos, los algoritmos voraces construyen el mejor objeto globalmente al elegir repetidamente la mejor opcion local.

\textbf{No aseguran una solucion optima en todos los casos}.

\subsection{Kruskal con Union-Find}
Dado un grafo, ¿cual es la cantidad minima de aristas (y las mas baratas), que me permitan conectar todo el grafo, de forma que exista un camino de un nodo a cualquier otro nodo?

\begin{lstlisting}
struct union_find{
    vector<int> e;
    union_find(int n) {e.assign(n, -1);}

    int findSet(int x) {return (e[x] < 0 ? x : e[x] = findSet(e[x]));}
    bool sameSet(int a, int b) {return findSet(a) == findSet(b);}
    bool size(int x) {return -e[findSet(x)];}

    bool unionSet(int x, int y){
        x = findSet(x), y = findSet(y);
        if(x == y) return 0;
        if(e[x] > e[y]) swap(x,y);
        e[x] += e[y], e[y] = x;
        return 1;
    }
};

struct Edge {
    int u, v, w; // origen, destino, peso
};

vector<Edge> kruskal(int n, vector<Edge> &edges){
    // 1. Ordenar aristas por peso
    sort(edges.begin(), edges.end(), [](const Edge &a, const Edge &b){return a.w < b.w;});

    // 2. Inicializar DSU
    union_find uf(n);
    vector<Edge> T;  // MST

    // 3. Recorrer aristas en orden creciente
    for(const Edge &e : edges){
        if(uf.findSet(e.u) != uf.findSet(e.v)){
            // Conecta dos componentes distintas
            T.push_back(e);
            uf.unionSet(e.u, e.v);
        }
    }

    // 4. Retornar el arbol generador minimo
    return T;
}
\end{lstlisting}

Complejidad Temporal: $O(E \log E)$, donde ordenar aristas domina sobre las operesaciones de DSU que toman $O(\alpha(E))$ \\
Complejidad Espacial: $O(n)$ para la estructura DSU mas el MST.

\subsection{Problema de Scheduling}
Se te da una lista de actividades $(s_1, e_1), \ldots, (s_n, e_n)$ denotadas por sus tiempos de inicio y finalizacion. Todas las actividades son igualmente atractivas para ti, y deseas maximizar el numero de actividades que realizas. \\
Objetivo: Escoger la mayor cantidad de actividades no superpuestas posible.

\begin{lstlisting}
struct Activity {
    int s, e; // start, end
};

vector<Activity> schedule(vector<Activity> &a){
    // 1. Ordenar por tiempo de finalizacion
    sort(a.begin(), a.end(), [](const Activity &x, const Activity &y){return x.e < y.e;});

    vector<Activity> chosen;

    if(a.empty()) return chosen;

    // 2. Seleccionar la primera actividad
    chosen.push_back(a[0]);
    int last_end = a[0].e;

    // 3. Recorrer el resto y tomar las compatibles
    for(int i = 1; i < a.size(); i++){
        if(a[i].s >= last_end){
            chosen.push_back(a[i]);
            last_end = a[i].e;
        }
    }

    return chosen;
}
\end{lstlisting}


Complejidad Temporal: $O(n \log n)$ debido a sort. \\
Complejidad Espacial: $O(n)$ en el peor caso donde todas las actividades son compatibles.

\subsection{Mochila fraccionaria}
Problema de la mochila clasico donde los objetos pueden ser divididos en partes mas pequeñas. \\
Objetivo: Maximizar el valor total en la mochila sin exceder su capacidad.

\begin{lstlisting}
struct Item {
    double value, weight;
};

double fractionalKnapsack(double W, vector<Item> &items){
    // 1. Ordenar por ratio (value/weight)
    sort(items.begin(), items.end(), [](const Item &a, const Item &b){
        return (a.value / a.weight) > (b.value / b.weight);});

    double totalValue = 0.0;

    // 2. Llenar la mochila
    for(const auto &it : items){
        if(W == 0) break;

        // Si cabe entero
        if(it.weight <= W){
            W -= it.weight;
            totalValue += it.value;
        }
        // Tomar fraccion
        else{
            double fraction = W / it.weight;
            totalValue += it.value * fraction;
            W = 0;
        }
    }

    return totalValue;
}
\end{lstlisting}

Complejidad Temporal: $O(n \log n)$ debido a sort. \\
Complejidad Espacial: $O(1)$ si se ordena in-place, $O(\log n)$ en caso contrario.

\subsection{Huffman}

Algoritmo de compresión de datos que asigna códigos binarios de longitud variable a los símbolos, basándose en su frecuencia de aparición.

\subsubsection*{Estructura del Nodo y Comparador}

\begin{lstlisting}
struct Node {
    char c;                // simbolo (solo en hojas)
    int freq;              // frecuencia del subarbol
    Node *left, *right;    // hijos

    Node(char c, int freq) : c(c), freq(freq), left(NULL), right(NULL) {}
    Node(Node* l, Node* r) : c('\0'), freq(l->freq + r->freq), left(l), right(r) {}
};

struct Compare {
    bool operator()(Node* a, Node* b) {
        return a->freq > b->freq; // min-heap
    }
};
\end{lstlisting}

\subsubsection*{Construcción del Árbol}

\begin{lstlisting}
Node* buildHuffmanTree(const unordered_map<char, int> &freq) {
    priority_queue<Node*, vector<Node*>, Compare> F;

    // 1. Crear un arbol para cada simbolo
    for (auto &p : freq) {
        F.push(new Node(p.first, p.second));
    }

    // 2. Fusionar arboles hasta tener uno solo
    while (F.size() > 1) {
        Node* T1 = F.top(); F.pop();
        Node* T2 = F.top(); F.pop();
        F.push(new Node(T1, T2));
    }

    return F.top();
}
\end{lstlisting}

\begin{multicols}{2}
\subsubsection*{Generación de Códigos}

\begin{lstlisting}
void generateCodes(Node* root, 
                   string code, 
                   unordered_map<char, string> &mp) {
    if (!root) return;

    // Hoja: asignar codigo
    if (!root->left && !root->right) {
        mp[root->c] = code;
    }

    generateCodes(root->left,  code + "0", mp);
    generateCodes(root->right, code + "1", mp);
}
\end{lstlisting}

\columnbreak

\subsubsection*{Codificación}

\begin{lstlisting}
string encode(const string &text, 
              unordered_map<char,string> &codeMap) {
    string encoded;
    for (char c : text) 
        encoded += codeMap[c];
    return encoded;
}
\end{lstlisting}
\end{multicols}

\subsubsection*{Decodificación}

\begin{lstlisting}
string decode(Node* root, const string &encoded) {
    string result;
    Node* curr = root;

    for (char bit : encoded) {
        curr = (bit == '0') ? curr->left : curr->right;

        // Llegamos a una hoja
        if (!curr->left && !curr->right) {
            result += curr->c;
            curr = root; // volver a la raiz
        }
    }
    return result;
}
\end{lstlisting}

\subsubsection*{Ejemplo de Uso}

\begin{lstlisting}
int main() {
    string text = "huffman example";

    // Contar frecuencias
    unordered_map<char,int> freq;
    for (char c : text) freq[c]++;

    // Construir arbol y generar codigos
    Node* root = buildHuffmanTree(freq);
    unordered_map<char,string> codeMap;
    generateCodes(root, "", codeMap);

    // Codificar y decodificar
    string encoded = encode(text, codeMap);
    string decoded = decode(root, encoded);

    return 0;
}
\end{lstlisting}

\textbf{Complejidad Temporal:} $O(n \log n)$. Se inserta n nodos en la priority\_queue $O(n \log n)$ en total. Cada iteracion extraen dos nodos minimos con pop() $O(2(n-1) \cdot \log n) = O(n \log n)$. Cada fusion inserta un nuevo nodo $O((n-1) \log n) = O(n \log n)$. Todo lo demas es $O(1)$\\
\textbf{Complejidad Espacial:} $O(n)$. El arbol final tiene $2n-1$ nodos, priority\_queue tiene a lo mas $n$ nodos.
